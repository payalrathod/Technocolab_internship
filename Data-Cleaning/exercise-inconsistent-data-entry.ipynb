{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/inconsistent-data-entry).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you'll apply what you learned in the **Inconsistent data entry** tutorial.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.data_cleaning.ex5 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:28:09.198454Z","iopub.execute_input":"2022-06-21T17:28:09.198857Z","iopub.status.idle":"2022-06-21T17:28:09.204603Z","shell.execute_reply.started":"2022-06-21T17:28:09.198823Z","shell.execute_reply":"2022-06-21T17:28:09.203747Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Get our environment set up\n\nThe first thing we'll need to do is load in the libraries and dataset we'll be using.  We use the same dataset from the tutorial.","metadata":{}},{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# helpful modules\nimport fuzzywuzzy\nfrom fuzzywuzzy import process\nimport chardet\n\n# read in all our data\nprofessors = pd.read_csv(\"../input/pakistan-intellectual-capital/pakistan_intellectual_capital.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:28:12.511110Z","iopub.execute_input":"2022-06-21T17:28:12.512087Z","iopub.status.idle":"2022-06-21T17:28:12.525885Z","shell.execute_reply.started":"2022-06-21T17:28:12.512049Z","shell.execute_reply":"2022-06-21T17:28:12.525159Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Next, we'll redo all of the work that we did in the tutorial.","metadata":{}},{"cell_type":"code","source":"# convert to lower case\nprofessors['Country'] = professors['Country'].str.lower()\n# remove trailing white spaces\nprofessors['Country'] = professors['Country'].str.strip()\n\n# get the top 10 closest matches to \"south korea\"\ncountries = professors['Country'].unique()\nmatches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\ndef replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n    # get a list of unique strings\n    strings = df[column].unique()\n    \n    # get the top 10 closest matches to our input string\n    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n    # only get matches with a ratio > 90\n    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n\n    # get the rows of all the close matches in our dataframe\n    rows_with_matches = df[column].isin(close_matches)\n\n    # replace all rows with close matches with the input matches \n    df.loc[rows_with_matches, column] = string_to_match\n    \n    # let us know the function's done\n    print(\"All done!\")\n    \nreplace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")\ncountries = professors['Country'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:28:16.720390Z","iopub.execute_input":"2022-06-21T17:28:16.721296Z","iopub.status.idle":"2022-06-21T17:28:16.736854Z","shell.execute_reply.started":"2022-06-21T17:28:16.721242Z","shell.execute_reply":"2022-06-21T17:28:16.735615Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# 1) Examine another column\n\nWrite code below to take a look at all the unique values in the \"Graduated from\" column.","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here\na = professors['Graduated from'].unique()\n\na.sort()\na","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:28:20.714592Z","iopub.execute_input":"2022-06-21T17:28:20.715265Z","iopub.status.idle":"2022-06-21T17:28:20.724520Z","shell.execute_reply.started":"2022-06-21T17:28:20.715217Z","shell.execute_reply":"2022-06-21T17:28:20.723497Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Do you notice any inconsistencies in the data?  Can any of the inconsistencies in the data be fixed by removing white spaces at the beginning and end of cells?\n\nOnce you have answered these questions, run the code cell below to get credit for your work.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq1.check()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:28:28.733281Z","iopub.execute_input":"2022-06-21T17:28:28.733668Z","iopub.status.idle":"2022-06-21T17:28:28.741567Z","shell.execute_reply.started":"2022-06-21T17:28:28.733629Z","shell.execute_reply":"2022-06-21T17:28:28.740456Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Line below will give you a hint\n#q1.hint()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Do some text pre-processing\n\nConvert every entry in the \"Graduated from\" column in the `professors` DataFrame to remove white spaces at the beginning and end of cells.","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here\n# professors['Graduated from'] = professors['Graduated from'].str.strip()\n# professors['Graduated from'] = professors['Graduated from'].str.strip()\nprofessors['Graduated from'] = professors['Graduated from'].str.strip()\n\n# Check your answer\nq2.check()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:28:33.989988Z","iopub.execute_input":"2022-06-21T17:28:33.990529Z","iopub.status.idle":"2022-06-21T17:28:34.001268Z","shell.execute_reply.started":"2022-06-21T17:28:33.990500Z","shell.execute_reply":"2022-06-21T17:28:34.000374Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n# q2.hint()\n# q2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:22:47.398764Z","iopub.execute_input":"2022-06-21T17:22:47.399614Z","iopub.status.idle":"2022-06-21T17:22:47.403499Z","shell.execute_reply.started":"2022-06-21T17:22:47.399578Z","shell.execute_reply":"2022-06-21T17:22:47.402504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Continue working with countries\n\nIn the tutorial, we focused on cleaning up inconsistencies in the \"Country\" column.  Run the code cell below to view the list of unique values that we ended with.","metadata":{}},{"cell_type":"code","source":"# get all the unique values in the 'City' column\ncountries = professors['Country'].unique()\n\n# sort them alphabetically and then take a closer look\ncountries.sort()\ncountries","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:28:38.373863Z","iopub.execute_input":"2022-06-21T17:28:38.374427Z","iopub.status.idle":"2022-06-21T17:28:38.381188Z","shell.execute_reply.started":"2022-06-21T17:28:38.374396Z","shell.execute_reply":"2022-06-21T17:28:38.380344Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Take another look at the \"Country\" column and see if there's any more data cleaning we need to do.\n\nIt looks like 'usa' and 'usofa' should be the same country.  Correct the \"Country\" column in the dataframe to replace 'usofa' with 'usa'.\n\n**Use the most recent version of the DataFrame (with the whitespaces at the beginning and end of cells removed) from question 2.**","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here!\n# def replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n#     strings = df[column].unique()\n#     matches = fuzzywuzzy.process.extract(string_to_match, strings,limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n#     close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n#     rows_with_matches = df[column].isin(close_matches)\n#     df.loc[rows_with_matches, column] = string_to_match\n#     print(\"All done!\")\nmatches = fuzzywuzzy.process.extract(\"usa\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\nreplace_matches_in_column(df=professors, column='Country', string_to_match=\"usa\", min_ratio=70)\n# matches = fuzzywuzzy.process.extract(\"usa\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n# replace_matches_in_column(df=professors, column='Graduated from', string_to_match=\"usa\")\n# Check your answer\n\nq3.check()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:30:21.267974Z","iopub.execute_input":"2022-06-21T17:30:21.268990Z","iopub.status.idle":"2022-06-21T17:30:21.282997Z","shell.execute_reply.started":"2022-06-21T17:30:21.268950Z","shell.execute_reply":"2022-06-21T17:30:21.282067Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"a = professors['Graduated from'].unique()\n\na.sort()\na","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:30:43.618282Z","iopub.execute_input":"2022-06-21T17:30:43.618622Z","iopub.status.idle":"2022-06-21T17:30:43.627500Z","shell.execute_reply.started":"2022-06-21T17:30:43.618596Z","shell.execute_reply":"2022-06-21T17:30:43.626328Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq3.hint()\n# q3.solution()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:30:50.912507Z","iopub.execute_input":"2022-06-21T17:30:50.913351Z","iopub.status.idle":"2022-06-21T17:30:50.921273Z","shell.execute_reply.started":"2022-06-21T17:30:50.913315Z","shell.execute_reply":"2022-06-21T17:30:50.920407Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# Congratulations!\n\nCongratulations for completing the **Data Cleaning** course on Kaggle Learn!\n\nTo practice your new skills, you're encouraged to download and investigate some of [Kaggle's Datasets](https://www.kaggle.com/datasets).","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*","metadata":{}}]}